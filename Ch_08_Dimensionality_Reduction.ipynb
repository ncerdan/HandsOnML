{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch_08_Dimensionality_Reduction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP5hXW6h/CNTsDFmZEIs6NZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNLBB_N4l39E",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ncerdan/HandsOnML/blob/master/Ch_08_Dimensionality_Reduction.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHVDkivdmX58",
        "colab_type": "text"
      },
      "source": [
        "# PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUk2uVGPmaZZ",
        "colab_type": "text"
      },
      "source": [
        "## Principal Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkUgWbWtm3Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a 3D dataset\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(4)\n",
        "m = 60\n",
        "w1, w2 = 0.1, 0.3\n",
        "noise = 0.1\n",
        "\n",
        "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "X = np.empty((m, 3))\n",
        "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
        "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05aap6CBlwFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you can compute them by hand using svd\n",
        "# if computing by hand, be sure to center the dataset!\n",
        "\n",
        "# compute svd\n",
        "X_centered = X - X.mean(axis=0)\n",
        "U, s, vT = np.linalg.svd(X_centered)\n",
        "\n",
        "# extract the first two PCs\n",
        "c1 = vT.T[:, 0]\n",
        "c2 = vT.T[:, 1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuLPjM3DnbbK",
        "colab_type": "text"
      },
      "source": [
        "## Projecting Down into d Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQTBeFQSnUgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to project into d-dimensions, just use the first d PCs\n",
        "# here: w=2\n",
        "\n",
        "W_2 = vT.T[:, :2]\n",
        "X_2D = X_centered.dot(W_2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2YvV1nJoWbG",
        "colab_type": "text"
      },
      "source": [
        "## Using Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHrq2oaEoTY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b73a35af-cf7f-430c-d0a6-94be971db803"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)   # projects to 2-D\n",
        "X_2D = pca.fit_transform(X)\n",
        "\n",
        "# the components_ attr holds the W_d matrix used\n",
        "print('Components:', pca.components_)\n",
        "\n",
        "# this would be the first PC\n",
        "print('First PC:', pca.components_.T[:, 0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Components: [[-0.93636116 -0.29854881 -0.18465208]\n",
            " [ 0.34027485 -0.90119108 -0.2684542 ]]\n",
            "First PC: [-0.93636116 -0.29854881 -0.18465208]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x0yFRfupOMp",
        "colab_type": "text"
      },
      "source": [
        "## Explained Variance Ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di2KhNNvpGFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8abf8fbc-b522-41c9-c147-fd882d07c649"
      },
      "source": [
        "# shows how much variance each PC contains\n",
        "pca.explained_variance_ratio_   # as you can see, the third PC only would have 2%"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.84248607, 0.14631839])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_wHG8Awp0ty",
        "colab_type": "text"
      },
      "source": [
        "## Choosing the Right Number of Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo4wfmw2qn6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first lets load in MNIST\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist_target = mnist.target.astype(np.uint8)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8FRdLUlrDN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and partition it\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = mnist['data']\n",
        "y = mnist['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuQ5rYmLprIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f2b78b-71fb-48df-8cb0-eafbb6328244"
      },
      "source": [
        "# here, we can use pca without reducing the data then pick the smallest\n",
        "# dimension that maintains at least 95% of the variance\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(X_train)\n",
        "cumulativeSum = np.cumsum(pca.explained_variance_ratio_)\n",
        "d = np.argmax(cumulativeSum >= 0.95) + 1\n",
        "print(d)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sF20pSErlIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# then we could run\n",
        "pca = PCA(n_components=d)\n",
        "X_reduced = pca.fit_transform(X_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRShbiWxsEUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# however, instead of this, this is built in to the PCA class\n",
        "# if you pass a float between 0 and 1 it will assume you are \n",
        "# setting the minimum variance retained:\n",
        "\n",
        "pca = PCA(n_components=0.95)\n",
        "X_reduced = pca.fit_transform(X_train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8cetrowsn-y",
        "colab_type": "text"
      },
      "source": [
        "## PCA for Compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwgzk1L3sad5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this code 'compresses' the data, but then also reconstructs it\n",
        "pca = PCA(n_components=154)\n",
        "X_reduced = pca.fit_transform(X_train)\n",
        "X_recovered = pca.inverse_transform(X_reduced)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxM4cYEmD-o6",
        "colab_type": "text"
      },
      "source": [
        "## Randomized PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbsmutrfD0B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the svd_solver='randomized' uses a stochastic PCA algo\n",
        "#   the default value is 'auto' where sklearn uses the following values:\n",
        "#       'randomized': if m or n is greater than 500 and d is less than 80% of m or n\n",
        "#       'full' approach: otherwise\n",
        "\n",
        "rnd_pca = PCA(n_components=154, svd_solver='randomized')\n",
        "X_reduced = rnd_pca.fit_transform(X_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUqujZbFE1yk",
        "colab_type": "text"
      },
      "source": [
        "## Incremental PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0NxKqDJEei7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "\n",
        "# does mini-batches of size 100\n",
        "n_batches = 100\n",
        "inc_pca = IncrementalPCA(n_components=154)\n",
        "for X_batch in np.array_split(X_train, n_batches):\n",
        "    inc_pca.partial_fit(X_batch)\n",
        "\n",
        "X_reduced = inc_pca.transform(X_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIJkOGOiFlFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you could also use numpy's memmap class which allows you to operate on binary data \n",
        "# on disk as if it is all in memory\n",
        "\n",
        "# X_mm = np.memmap(filename, dtype='float32', mode='readonly', shape=(m, n))\n",
        "\n",
        "# batch_size = m // n_batches\n",
        "# inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
        "# inc_pca.fit(X_mm)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv4LjXtRGFju",
        "colab_type": "text"
      },
      "source": [
        "# Kernal PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DTTEFMYGDEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# would use sklearn's KernelPCA class imported as follows\n",
        "from sklearn.decomposition import KernelPCA"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIrprFnAHW9I",
        "colab_type": "text"
      },
      "source": [
        "## Selecting a Kernel and Tuning Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEn0R2tfHVvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creates a simple 2-step pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = Pipeline([\n",
        "    ('kpca', KernelPCA(n_components=2)),\n",
        "    ('log_reg', LogisticRegression())\n",
        "])\n",
        "\n",
        "param_grid = [{\n",
        "    'kpca__gamma': np.linspace(0.03, 0.05, 5),\n",
        "    'kpca__kernel': ['rbf', 'sigmoid']\n",
        "}]\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gfjQau6K-c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}