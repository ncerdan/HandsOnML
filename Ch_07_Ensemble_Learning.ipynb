{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch_07_Ensemble_Learning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCov6bPj1kbKX9VZN8TfKU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ek4c6viOlbV",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ncerdan/HandsOnML/blob/master/Ch_07_Ensemble_Learning.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2QztlI7Op97",
        "colab_type": "text"
      },
      "source": [
        "# Voting Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twIQDAcWOt0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make several predictors and a hard voting of all of them combined\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
        "    voting='hard'\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSD8yDQiQ0Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's get the data\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_moons(n_samples=10000, noise=0.3, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5BKtRK7QE73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b8518e32-e40c-4e65-b8b1-b1099b56b524"
      },
      "source": [
        "# lets look at all of their performances\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))   # in theory, voting should do best"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression 0.8685\n",
            "RandomForestClassifier 0.9175\n",
            "SVC 0.926\n",
            "VotingClassifier 0.927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqPSG9ojRWys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c0fb8a24-fe57-4b3e-c2d3-94d726f36304"
      },
      "source": [
        "# can do a similar thing with soft voting too!\n",
        "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma=\"scale\", random_state=42, probability=True)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))   # in theory, voting should do even better here"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression 0.8685\n",
            "RandomForestClassifier 0.9175\n",
            "SVC 0.926\n",
            "VotingClassifier 0.9275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfRE_2zKWSC5",
        "colab_type": "text"
      },
      "source": [
        "# Bagging and Pasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GlB4cZ-WJCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09ce6b4e-4cf7-42a9-9976-cf33df77f7a1"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    max_samples=100, bootstrap=True, n_jobs=-1      # if bootstrap=False --> pasting\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hfS7b23ZCxj",
        "colab_type": "text"
      },
      "source": [
        "## Out-of-Bag Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYPl_ctCYAic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f9d78ad-65e8-49ed-fe0d-441d3ff2b1ed"
      },
      "source": [
        "# sklearn has out-of-bag scoring built in!\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    bootstrap=True, n_jobs=-1, oob_score=True\n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.900875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kncBE-LvZgH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0c92e1f-7aa2-492a-bd2f-c346eb808714"
      },
      "source": [
        "# oob says we should get around 90% when testing, let's check\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)      # got close to 90%!"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CvD3Vj4Z_UT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4beff120-3afd-4e69-a34c-13d3a4a22fd0"
      },
      "source": [
        "# the decision function scores of each estimator from oob is also available\n",
        "bag_clf.oob_decision_function_  # shows prob of each classification"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.78443114, 0.21556886],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       ...,\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.9       , 0.1       ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nEK9IEjbBby",
        "colab_type": "text"
      },
      "source": [
        "# Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDFZOft0aOCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "393a0fc4-85fb-48eb-834f-a09262cbb626"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred_rf)       # does well!"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.929"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N9CUqOdd_AB",
        "colab_type": "text"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3A52JAtcBeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "84a7f241-c4e0-4e62-bbdc-a432463e7f75"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
        "rnd_clf.fit(iris['data'], iris['target'])\n",
        "\n",
        "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
        "    print(name, score)\n",
        "\n",
        "# shows that petal information is much more important than sepal information"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sepal length (cm) 0.10746968265669561\n",
            "sepal width (cm) 0.024521716837023855\n",
            "petal length (cm) 0.41832037697946844\n",
            "petal width (cm) 0.4496882235268121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onf43xzXen1y",
        "colab_type": "text"
      },
      "source": [
        "# Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OXvJzPkgIqJ",
        "colab_type": "text"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_YgLlW2eYxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a07c899f-e245-4eec-c553-858cdfda56d0"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    algorithm='SAMME.R', learning_rate=0.5\n",
        ")\n",
        "ada_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ada = ada_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred_ada)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.912"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "859x-rVQgoPm",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ivNZQaihmPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's make simple one from scratch"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeaLsr2egYuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make noisy quadractic dataset\n",
        "import numpy as np\n",
        "m = 100\n",
        "X = 6 * np.random.rand(m, 1) - 3\n",
        "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\n",
        "y = y.ravel()\n",
        "y1 = y"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wIz9BIBhpMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9443b2f8-c178-4f2c-ac90-0bdb0c55628e"
      },
      "source": [
        "# train first one\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg1.fit(X, y1)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eig6pgYqhww8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8ab64cb4-dde5-4823-9fdc-e9ccf9315093"
      },
      "source": [
        "# now train the second one on the errors from the first\n",
        "y2 = y1 - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZdmF-b3iDW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7149f47f-1ca3-4c75-aeb6-bad21e0a0cff"
      },
      "source": [
        "# now train the third on the errors from the second\n",
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
              "                      max_features=None, max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                      random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzY6TMYpiVlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# can make predictions on some X_new by summing all three together like so:\n",
        "# y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKLe8AWGirn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f0e36e51-070e-4b18-fe2a-afbe22725a4c"
      },
      "source": [
        "# could also just use builtin class to do the same thing\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
        "gbrt.fit(X, y)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=1.0, loss='ls', max_depth=2,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=3,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ4A5WSGjG1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e6c1fd9e-5096-4504-f599-119aed03e017"
      },
      "source": [
        "# using early stopping to find right number of trees in GBRT by analyzing\n",
        "# a GBRT with too many trees first\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=80)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='ls', max_depth=2,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=18,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae0mdM7Gk1Cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "061d352e-28b1-4c37-b05c-2577903e4f6c"
      },
      "source": [
        "# could also use warm_start=True\n",
        "# this makes it keep existing tress when the fit() method is called\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
        "\n",
        "min_val_error = float('inf')\n",
        "error_going_up = 0\n",
        "for n_estimators in range(1, 80):\n",
        "    gbrt.n_estimators = n_estimators\n",
        "    gbrt.fit(X_train, y_train)\n",
        "    y_pred = gbrt.predict(X_val)\n",
        "    val_error = mean_squared_error(y_val, y_pred)\n",
        "    if val_error < min_val_error:\n",
        "        min_val_error = val_error\n",
        "        error_going_up = 0\n",
        "    else:\n",
        "        error_going_up += 1\n",
        "        if error_going_up == 5:\n",
        "            break   # early stop if error has gone up 5 times in a row\n",
        "\n",
        "gbrt"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
              "                          init=None, learning_rate=0.1, loss='ls', max_depth=2,\n",
              "                          max_features=None, max_leaf_nodes=None,\n",
              "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                          min_samples_leaf=1, min_samples_split=2,\n",
              "                          min_weight_fraction_leaf=0.0, n_estimators=23,\n",
              "                          n_iter_no_change=None, presort='deprecated',\n",
              "                          random_state=None, subsample=1.0, tol=0.0001,\n",
              "                          validation_fraction=0.1, verbose=0, warm_start=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhtFJA1EnUwt",
        "colab_type": "text"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCLaZMyMlsjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "769ff662-6ec0-49a7-8508-1abee0b0b029"
      },
      "source": [
        "# a third-party api for optimized Gradient Boosting\n",
        "import xgboost\n",
        "\n",
        "xgb_reg = xgboost.XGBRegressor()\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[04:13:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuwKmWBunpIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "24084349-c267-4418-a920-fe52568c02c6"
      },
      "source": [
        "# also has builtin early stopping!\n",
        "xgb_reg.fit(X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[04:14:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:3.93158\n",
            "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
            "[1]\tvalidation_0-rmse:3.60901\n",
            "[2]\tvalidation_0-rmse:3.31095\n",
            "[3]\tvalidation_0-rmse:3.05212\n",
            "[4]\tvalidation_0-rmse:2.81744\n",
            "[5]\tvalidation_0-rmse:2.60604\n",
            "[6]\tvalidation_0-rmse:2.426\n",
            "[7]\tvalidation_0-rmse:2.27088\n",
            "[8]\tvalidation_0-rmse:2.12541\n",
            "[9]\tvalidation_0-rmse:2.00462\n",
            "[10]\tvalidation_0-rmse:1.90452\n",
            "[11]\tvalidation_0-rmse:1.8108\n",
            "[12]\tvalidation_0-rmse:1.736\n",
            "[13]\tvalidation_0-rmse:1.68088\n",
            "[14]\tvalidation_0-rmse:1.61243\n",
            "[15]\tvalidation_0-rmse:1.57084\n",
            "[16]\tvalidation_0-rmse:1.53811\n",
            "[17]\tvalidation_0-rmse:1.4999\n",
            "[18]\tvalidation_0-rmse:1.46648\n",
            "[19]\tvalidation_0-rmse:1.44737\n",
            "[20]\tvalidation_0-rmse:1.43347\n",
            "[21]\tvalidation_0-rmse:1.42763\n",
            "[22]\tvalidation_0-rmse:1.42798\n",
            "[23]\tvalidation_0-rmse:1.42113\n",
            "[24]\tvalidation_0-rmse:1.41035\n",
            "[25]\tvalidation_0-rmse:1.40777\n",
            "[26]\tvalidation_0-rmse:1.39827\n",
            "[27]\tvalidation_0-rmse:1.39926\n",
            "[28]\tvalidation_0-rmse:1.40699\n",
            "Stopping. Best iteration:\n",
            "[26]\tvalidation_0-rmse:1.39827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKaDHVDTn8ns",
        "colab_type": "text"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w05jSPr7ql8R",
        "colab_type": "text"
      },
      "source": [
        "## 8.) TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRd7TbyIqpbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFr3jHDkqp2y",
        "colab_type": "text"
      },
      "source": [
        "## 9.) TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NF4_f3bqrAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}